If all you have is a stream of “beat candidates” with time intervals between them (IOIs = inter-onset intervals), and you *can’t* yet label kick/snare/hh, the smartest tempo detector is basically:

1. **build a tempo hypothesis from IOIs**
2. **handle subdivisions/multiples** (because you’ll detect 8ths/16ths, not just quarter notes)
3. **track tempo over time** (don’t re-estimate from scratch every hit)

Here’s a solid, practical way to do it:

---

## 1. Keep a rolling IOI buffer

Maintain the last N intervals (say 2–6 seconds worth).
Compute each new IOI when a hit is detected:
[
\text{IOI}*k = t_k - t*{k-1}
]

Reject obvious junk early:

* Ignore IOIs < 60 ms (double-triggers / noise)
* Ignore IOIs > 2 s (probably a fill gap / missing hits)

---

## 2. Convert IOIs to tempo candidates with folding

Each IOI implies a tempo:
[
\text{BPM} = \frac{60}{\text{IOI}}
]

But the IOI might be a subdivision (e.g., 8th note) or multiple (half note).
So **fold** every candidate into a plausible BPM range, e.g. 70–200 BPM:

Pseudo:

```text
bpm = 60 / ioi
while bpm < 70: bpm *= 2
while bpm > 200: bpm /= 2
```

This alone fixes most “it thinks 2× or ½× tempo” problems.

---

## 3. Make a weighted tempo histogram

Create bins over BPM (1 BPM resolution is fine).
For every folded BPM candidate, vote into the histogram.

**Weight votes** so more reliable IOIs count more:

* shorter IOIs (hi-hat 16ths) are less reliable for *quarter-note tempo*
* longer IOIs (backbeat spacing) are more reliable

A simple weight:
[
w = \min(1, \frac{\text{IOI}}{0.5\text{s}})
]
So IOIs near 0.5 s (~120 BPM quarter note) get high weight.

Optionally add a small Gaussian blur to histogram so near-misses cluster.

Pick the peak BPM = current tempo hypothesis.

---

## 4. Stabilize with a tempo tracker (PLL / Kalman-lite)

Instead of jumping to the new peak every hit, track smoothly.

Easy but effective:

```text
tempo_est = 0.9 * tempo_est + 0.1 * tempo_peak
```

Better: **phase-locked loop idea**
Predict next beat time from current tempo, compare to actual hit, nudge tempo & phase.

State:

* `T` = period (seconds per beat)
* `phi` = beat phase / predicted beat time

Update on each hit at time `t`:

```text
error = t - phi
phi += alpha * error        # phase correction
T   += beta  * error        # tempo correction (beta << alpha)
```

This makes the tempo “lock in” and ride through fills.

---

## 5. Handle fills / bursts robustly

Fills create lots of fast hits => histogram might drift to 2× or 4×.

Two guardrails:

1. **cap subdivision influence:** down-weight IOIs that are much shorter than current period:
   [
   w \leftarrow w \cdot \exp\left(-\left(\frac{\text{IOI}}{T/2}\right)^2\right)
   ]
2. **inertia:** don’t allow tempo to change > ~5–8% per second unless confidence is high.

---

## 6. Confidence score (so you know when you’re right)

Compute something like:
[
\text{conf} = \frac{\text{peak height}}{\text{sum of histogram}}
]
or peak / second-peak ratio.

Use confidence to decide:

* when to “publish” tempo
* when to freeze updates (low confidence during fills)

---

# Why this is “smart” for your case

Because with unlabeled drum hits:

* you *will* see subdivisions (hh) and syncopations
* sometimes you’ll miss the true downbeat
* but **IOI clustering still contains tempo** if you fold and aggregate

This approach needs no instrument classification and is computationally cheap—perfect for embedded/real-time.

---

# Extra upgrades (optional later)

* **Autocorrelation / tempogram** on an onset strength envelope (more robust, more CPU).
* **Meter inference (3/4 vs 4/4)** once you can label or detect accent patterns.
* **Kick/snare probability weighting** once your classifier exists.

---

If you want, I can sketch a minimal C/C#/ESP32-friendly implementation of the histogram+PLL combo tailored to your sampling/latency setup.
